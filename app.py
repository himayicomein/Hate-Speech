import pickle
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
import streamlit as st
import time
from googletrans import Translator

# ‡πÇ‡∏°‡πÄ‡∏î‡∏•
loaded_model = keras.models.load_model("C:/Users/Narissara/OneDrive/Desktop/NLP Project/hate_speech_modelv2.h5")

with open("C:/Users/Narissara/OneDrive/Desktop/NLP Project/label_encoder.pkl", "rb") as f:
    loaded_label_encoder = pickle.load(f)

with open("C:/Users/Narissara/OneDrive/Desktop/NLP Project/tokenizer.pkl", "rb") as f:
    loaded_tokenizer = pickle.load(f)

#‡∏ä‡∏∑‡πà‡∏≠ ‡∏â‡∏™‡∏ü‡∏´‡∏´
class_mapping = {
    0: "üö® Hate Speech",
    1: "‚ö†Ô∏è Offensive Language",
    2: "‚úÖ Neither"
}

# ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏î‡∏µ
advice_mapping = {
    "üö® Hate Speech": "‡πÇ‡∏õ‡∏£‡∏î‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ñ‡πâ‡∏≠‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î‡∏ä‡∏±‡∏á ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå",
    "‚ö†Ô∏è Offensive Language": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏õ‡∏£‡∏î‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡πÉ‡∏´‡πâ‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏Ç‡∏∂‡πâ‡∏ô"
}

# ‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
try:
    with open("history.json", "r", encoding="utf-8") as f:
        input_history = json.load(f)
except (FileNotFoundError, json.JSONDecodeError):
    input_history = []

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
def predict_text(text):
    # ‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á‡∏ï‡∏±‡∏ß
    translator = Translator()
    translated_text = translator.translate(text, src="auto", dest="en").text
    st.write(f"üìù Translated Text: {translated_text}")
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Padding
    sequence = loaded_tokenizer.texts_to_sequences([translated_text])
    padded = pad_sequences(sequence, maxlen=100, padding="post", truncating="post")
    prediction = loaded_model.predict(padded)
    predicted_class = np.argmax(prediction)
    result = class_mapping.get(predicted_class, "Unknown")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
    input_data = {"original_text": text, "translated_text": translated_text, "prediction": result}
    input_history.append(input_data)
    with open("history.json", "w", encoding="utf-8") as f:
        json.dump(input_history, f, indent=4, ensure_ascii=False)
    
    return result

# ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á UI Streamlit
st.set_page_config(page_title="Hate Speech Detection", page_icon="üö®", layout="centered")

st.markdown("""  
    <style>
        body {
            background-color: #1E1E1E;
            color: #FFFFFF;
            font-family: Arial, sans-serif;
        }
        .stTextArea textarea {
            background-color: #333;
            color: #FFF;
        }
        .stButton>button {
            background-color: #FF4B4B;
            color: white;
            font-size: 18px;
            padding: 10px 20px;
            border-radius: 8px;
        }
    </style>
    <h1 style="text-align:center; color:#FF4B4B;">‚ö†Ô∏è Hate Speech Detector</h1>
    <p style="text-align:center; font-size:18px; color:#FFFFFF;">‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó</p>
    <hr>
    """, unsafe_allow_html=True)

# ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
st.markdown("<h3>üìù Input your text below:</h3>", unsafe_allow_html=True)
user_input = st.text_area("üí¨ Enter your text:", height=150)

# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
if st.button("üîç Analyze Text"):
    if user_input.strip():
        prediction = predict_text(user_input)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ñ‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (Progress Bar) ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        progress = st.progress(0)
        for i in range(100):
            time.sleep(0.02)
            progress.progress(i + 1)

        if "Hate Speech" in prediction:
            st.error(f"{prediction}")
            st.warning(f"üí° Suggestion: {advice_mapping[prediction]}")
        elif "Offensive Language" in prediction:
            st.warning(f"{prediction}")
            st.info(f"üí° Suggestion: {advice_mapping[prediction]}")
        else:
            st.success(f"{prediction}")
            st.balloons()
    else:
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå!")

# ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
st.markdown("<h3>üìú History</h3>", unsafe_allow_html=True)
if input_history:
    for idx, entry in enumerate(reversed(input_history[-10:]), 1):  # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î 10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
        with st.expander(f"üîπ Entry {idx}"):
            st.write(f"**Original Text:** {entry['original_text']}")
            st.write(f"**Translated Text:** {entry['translated_text']}")
            st.write(f"**Prediction:** {entry['prediction']}")
else:
    st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
